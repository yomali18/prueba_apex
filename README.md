# prueba_apex

Pipeline ETL desarrollado en PySpark para el procesamiento de datos de entregas de productos.  El flujo implementa buenas prÃ¡cticas de ingenierÃ­a de datos: estandarizaciÃ³n de columnas, control de calidad, filtrado parametrizado, transformaciÃ³n de unidades y generaciÃ³n de mÃ©tricas.

---

## ğŸ“Œ Objetivo

Procesar un dataset de entregas de productos aplicando:

- Validaciones de calidad de datos
- Filtros dinÃ¡micos por rango de fechas y paÃ­s
- NormalizaciÃ³n de unidades
- ClasificaciÃ³n de tipos de entrega
- Enriquecimiento de mÃ©tricas
- ExportaciÃ³n particionada

---

## ğŸ—‚ï¸ Estructura del proyecto
[tree.txt](tree.txt)

