# prueba_apex

Pipeline ETL desarrollado en PySpark para el procesamiento de datos de entregas de productos.  
El flujo implementa buenas prÃ¡cticas de ingenierÃ­a de datos: estandarizaciÃ³n de columnas, control de calidad, filtrado parametrizado, transformaciÃ³n de unidades, generaciÃ³n de mÃ©tricas y reporte automÃ¡tico de calidad.

---

## ğŸ“Œ Objetivo

Procesar un dataset de entregas de productos aplicando:

- Validaciones de calidad de datos
- Filtros dinÃ¡micos por rango de fechas y paÃ­s
- NormalizaciÃ³n de unidades
- ClasificaciÃ³n de tipos de entrega
- Enriquecimiento de mÃ©tricas
- ExportaciÃ³n particionada
- GeneraciÃ³n de un reporte automÃ¡tico de datos

---

## ğŸ—‚ï¸ Estructura del proyecto

